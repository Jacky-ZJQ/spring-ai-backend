# ---------- Ports ----------
BACKEND_PORT=8080
PORTAL_PORT=80

# ---------- Frontend ----------
# 建议在容器内使用 /api，由前端 Nginx 反向代理到 backend
VITE_API_BASE_URL=/api

# ---------- Backend Common ----------
APP_LOG_LEVEL=info

# ---------- Database (external MySQL recommended) ----------
DB_URL=jdbc:mysql://<your-mysql-host>:3306/itheima?serverTimezone=Asia/Shanghai&useSSL=false&useUnicode=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull&transformedBitIsBoolean=true&tinyInt1isBit=false&allowPublicKeyRetrieval=true&allowMultiQueries=true&useServerPrepStmts=false
DB_USERNAME=root
DB_PASSWORD=123456

# ---------- LLM ----------
OPENAI_API_KEY=<your-openai-compatible-api-key>
OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode
OPENAI_CHAT_MODEL=qwen-max-latest
OPENAI_EMBEDDING_MODEL=text-embedding-v3

# 可选：如果你仍然要启用本地 Ollama，请设置可访问地址
# - Docker 内后端访问宿主机 Ollama：http://host.docker.internal:11434
# - 本机直接运行后端：http://localhost:11434
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_CHAT_MODEL=deepseek-r1:1.5b
SKILL_GENERAL_CLIENT_BEAN=ollamaChatClient

# ---------- Skills ----------
SKILLS_ENABLED=true

# ---------- MCP ----------
MCP_ENABLED=true
MCP_SERVER_NAME=spring-ai-mcp-gateway
MCP_SERVER_VERSION=1.0.0
MCP_SESSION_TTL_SECONDS=1800
MCP_AUTO_REGISTER_UNCONFIGURED_TOOLS=true
